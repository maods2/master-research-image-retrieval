# Paths and directories for training and testing data
data:
  train_dir: "datasets/final/terumo/train"
  test_dir: "datasets/final/terumo/test"
  class_mapping:
    Crescent: 0
    Hypercellularity: 1
    Membranous: 2
    Normal: 3
    Podocytopathy: 4
    Sclerosis: 5
  batch_size: 64
  num_workers: 3  # Number of workers to load the data

# Transformation configuration for image preprocessing
transform:
  resize: [224, 224]  # Resize images to 224x224
  horizontal_flip: true  # Apply random horizontal flip
  vertical_flip: true  # Apply random vertical flip
  rotation:
    max_angle: 30  # Maximum rotation angle
    probability: 0.5  # Probability of applying rotation
  color_jitter:
    brightness: 0.2  # Brightness factor
    contrast: 0.2  # Contrast factor
    saturation: 0.2  # Saturation factor
    hue: 0.1  # Hue factor
    probability: 0.5  # Probability of applying color jitter
  gaussian_noise:
    var_limit: [10, 50]  # Variance range for Gaussian noise
    mean: 0  # Mean for Gaussian noise
    probability: 0.5  # Probability of applying Gaussian noise
  gaussian_blur:
    blur_limit: [3, 7]  # Kernel size limit for Gaussian blur
    probability: 0.5  # Probability of applying Gaussian blur
  coarse_dropout:
    max_holes: 8  # Maximum number of holes
    max_height: 16  # Maximum height of holes
    max_width: 16  # Maximum width of holes
    min_holes: 1  # Minimum number of holes
    min_height: 4  # Minimum height of holes
    min_width: 4  # Minimum width of holes
    probability: 0.5  # Probability of applying coarse dropout
  distortion:
    optical_distortion: 0.5  # Probability of applying optical distortion
    grid_distortion: 0.5  # Probability of applying grid distortion
    piecewise_affine: 0.5  # Probability of applying piecewise affine
    probability: 0.5  # Probability of applying one of the distortions
  shift_scale_rotate:
    shift_limit: 0.0625  # Limit for shifting
    scale_limit: 0.1  # Limit for scaling
    rotate_limit: 45  # Limit for rotation
    probability: 0.5  # Probability of applying shift-scale-rotate
  normalize:
    mean: [0.5, 0.5, 0.5]  # Normalize mean
    std: [0.5, 0.5, 0.5]   # Normalize std
  to_tensor: true  # Convert to tensor (default is true)

# Model configuration
model:
  name: "resnet50"  # Example: You can set it to resnet18, resnet34, etc.
  experiment_name: "multilable"  # Name of the experiment
  pretrained: true  # Use pre-trained weights
  num_classes: 6  # Number of classes in the dataset
  load_checkpoint: true  # Load a pre-trained model checkpoint
  checkpoint_path: "./artifacts/multilable_resnet50_2025-01-28_03-18-23_checkpoint.pth"  # Path to the model checkpoint

# Loss function configuration
loss:
  name: "bce"  # Specify the loss function (cross_entropy, etc.)

# Optimizer configuration
optimizer:
  name: "adam"  # Specify the optimizer (adam, sgd, etc.)
  lr: 0.001  # Learning rate
  weight_decay: 1e-4  # Weight decay for regularization

# Training configuration
training:
  pipeline: "train_multilabel"  # The pipeline to run (e.g., train, finetune, etc.)
  epochs: 60  # Number of epochs to train
  lr_scheduler:
    name: "step_lr"  # Learning rate scheduler (step_lr, cosine_annealing, etc.)
    step_size: 10  # Step size for scheduler (for step_lr)

testing:
  pipeline: "default"  # The pipeline to run (e.g., default, retrieval, etc.)
  list_of_metrics:
    - type: accuracy
    - type: f1_score
    # - type: precision
    # - type: recall
    - type: map@k
      k_values: [1, 3, 5, 10]
    - type: precision@k
      k_values: [1, 3, 5, 10]
    - type: recall@k
      k_values: [1, 3, 5, 10]
    - type: accuracy@k
      k_values: [1, 3, 5, 10]

# Logging configuration
logging:
  log_file: "./logs.txt"  # file to save logs
  log_level: "INFO"  # Set logging level (DEBUG, INFO, WARNING, ERROR)

metric_logging:
  tool: "mlflow"  # Tool to log metrics (txt, csv, mlflow, etc.)
  
# Output configuration
output:
  model_dir: "./artifacts"  # Directory to save model artifacts
  results_dir: "."  # Directory to save results


