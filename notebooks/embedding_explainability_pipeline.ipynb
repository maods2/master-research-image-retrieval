{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "import numpy as np\n\ndata = np.load(\"fake_embeddings.npy\", allow_pickle=True).item()\n\ndb_embeddings = data[\"db_embeddings\"]\ndb_labels = data[\"db_labels\"]\ndb_paths = data[\"db_paths\"]\nquery_embeddings = data[\"query_embeddings\"]"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "from sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\npca = PCA(n_components=2)\ndb_proj = pca.fit_transform(db_embeddings)\n\nplt.figure(figsize=(8, 6))\nfor label in np.unique(db_labels):\n    idxs = db_labels == label\n    plt.scatter(db_proj[idxs, 0], db_proj[idxs, 1], label=label, alpha=0.6)\nplt.title(\"Espa\u00e7o PCA dos Embeddings\")\nplt.legend()\nplt.show()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\n\nclf = LogisticRegression(max_iter=1000)\nscores = cross_val_score(clf, db_embeddings, db_labels, cv=5)\nprint(f\"Acur\u00e1cia m\u00e9dia (Probing): {scores.mean():.2f}\")"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "from sklearn.metrics.pairwise import cosine_distances\n\ndef get_top_k(query_emb, db_embs, k=5):\n    dists = cosine_distances(query_emb.reshape(1, -1), db_embs).flatten()\n    top_k = np.argsort(dists)[:k]\n    return top_k, dists[top_k]\n\nquery_id = 0\ntop_ids, top_dists = get_top_k(query_embeddings[query_id], db_embeddings)\nfor i, idx in enumerate(top_ids):\n    print(f\"{i+1}. {db_paths[idx]} (dist={top_dists[i]:.4f})\")"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "import torch\nimport timm\nimport torchvision.transforms as T\nfrom PIL import Image\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nuse_vit = True  # ou False para ResNet + Grad-CAM\n\nif use_vit:\n    model = timm.create_model(\"vit_base_patch16_224\", pretrained=True).to(device)\nelse:\n    model = timm.create_model(\"resnet50\", pretrained=True).to(device)\n\nmodel.eval()\n\ntransform = T.Compose([\n    T.Resize((224, 224)),\n    T.ToTensor(),\n    T.Normalize([0.5]*3, [0.5]*3),\n])"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "def vit_attention_rollout(model, img_tensor):\n    attn_blocks = [blk.attn.attn_drop for blk in model.blocks]\n    img_tensor = img_tensor.unsqueeze(0).to(device)\n    with torch.no_grad():\n        _ = model.forward_features(img_tensor)\n\n    attn = model.blocks[-1].attn.get_attn()\n    attn = attn[0].mean(0)\n    mask = attn[0, 1:].reshape(14, 14).cpu().numpy()\n    return mask"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "from torchvision.models.feature_extraction import create_feature_extractor\n\ndef gradcam_resnet(model, img_tensor):\n    model.eval()\n    features = {}\n\n    def hook_fn(m, i, o): features[\"feat\"] = o\n\n    handle = model.layer4.register_forward_hook(hook_fn)\n    img_tensor = img_tensor.unsqueeze(0).to(device)\n    model(img_tensor)\n    act = features[\"feat\"].squeeze(0).mean(0).cpu().numpy()\n    handle.remove()\n    return act"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef visualize_explainability(img_path, use_vit=True):\n    img = Image.open(img_path).convert(\"RGB\")\n    img_tensor = transform(img)\n\n    if use_vit:\n        mask = vit_attention_rollout(model, img_tensor)\n        mask = cv2.resize(mask, img.size)\n    else:\n        mask = gradcam_resnet(model, img_tensor)\n        mask = cv2.resize(mask, img.size)\n\n    mask = (mask - np.min(mask)) / (np.max(mask) - np.min(mask) + 1e-8)\n    heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)\n    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n    overlay = np.array(img) * 0.5 + heatmap * 0.5\n\n    plt.figure(figsize=(10, 4))\n    plt.subplot(1, 3, 1)\n    plt.imshow(img)\n    plt.title(\"Imagem original\")\n    plt.axis(\"off\")\n    plt.subplot(1, 3, 2)\n    plt.imshow(heatmap)\n    plt.title(\"Mapa de aten\u00e7\u00e3o\")\n    plt.axis(\"off\")\n    plt.subplot(1, 3, 3)\n    plt.imshow(overlay.astype(np.uint8))\n    plt.title(\"Sobreposi\u00e7\u00e3o\")\n    plt.axis(\"off\")\n    plt.show()\n\n# visualize_explainability(\"/caminho/para/imagem.jpg\", use_vit=True)"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}